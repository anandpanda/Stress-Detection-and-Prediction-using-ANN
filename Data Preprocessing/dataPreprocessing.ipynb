{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "data_path = '../Dataset/Human Stress Dataset.csv'\n",
    "dataset = pd.read_csv(data_path)\n",
    "df = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical and Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Columns:\n",
      "Index(['Snoring Rate', 'Respiratory Rate', 'Body Temperature', 'Limb Movement',\n",
      "       'Blood Oxygen', 'Eye Movement', 'Sleep Hours', 'Heart Rate'],\n",
      "      dtype='object')\n",
      "\n",
      "Categorical Columns:\n",
      "Index(['Stress Levels'], dtype='object')\n",
      "\n",
      "Unique values in column Stress Levels\n",
      "['stressed' 'not stressed']\n"
     ]
    }
   ],
   "source": [
    "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "print(\"Numerical Columns:\")\n",
    "print(numerical_cols)\n",
    "\n",
    "print(\"\\nCategorical Columns:\")\n",
    "print(categorical_cols)\n",
    "\n",
    "for col in categorical_cols:\n",
    "    # print all the unique values in the column\n",
    "    print(\"\\nUnique values in column\", col)\n",
    "    print(df[col].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing values found in the dataset.\n"
     ]
    }
   ],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "\n",
    "# If there are missing values, impute them\n",
    "if missing_values.any():\n",
    "    print(\"Missing values found. Imputing missing values...\")\n",
    "    \n",
    "    # Handling missing values for numerical columns by filling with mean\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    df[numerical_cols] = imputer.fit_transform(df[numerical_cols])\n",
    "\n",
    "    # Handling missing values for categorical columns by filling with most frequent value\n",
    "    imputer_cat = SimpleImputer(strategy='most_frequent')\n",
    "    df[categorical_cols] = imputer_cat.fit_transform(df[categorical_cols])\n",
    "\n",
    "    print(\"Missing values have been imputed.\")\n",
    "else:\n",
    "    print(\"No missing values found in the dataset.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.isnull().sum(), it returns a Series where the index is the column names, and the value for each column is the number of missing values in that column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding Categorical Variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   Snoring Rate  Respiratory Rate  Body Temperature  Limb Movement  \\\n",
      "0         93.80            25.680            91.840         16.600   \n",
      "1         91.64            25.104            91.552         15.880   \n",
      "2         60.00            20.000            96.000         10.000   \n",
      "3         85.76            23.536            90.768         13.920   \n",
      "4         48.12            17.248            97.872          6.496   \n",
      "\n",
      "   Blood Oxygen  Eye Movement  Sleep Hours  Heart Rate Stress Levels  \n",
      "0        89.840         99.60        1.840       74.20      stressed  \n",
      "1        89.552         98.88        1.552       72.76      stressed  \n",
      "2        95.000         85.00        7.000       60.00  not stressed  \n",
      "3        88.768         96.92        0.768       68.84      stressed  \n",
      "4        96.248         72.48        8.248       53.12  not stressed  \n"
     ]
    }
   ],
   "source": [
    "print(\"Original DataFrame:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Label Encoding:** This method assigns each unique category a numeric label. It's useful when the categorical feature has an inherent order (ordinal data), like \"Low\", \"Medium\", \"High\".\n",
    "\n",
    "Here, stress Levels are not ordinal, but the encoding would still work as it maps it alphabetically \\\n",
    "not stressed -> 0 \\\n",
    "stressed -> 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame with Label Encoding :\n",
      "   Snoring Rate  Respiratory Rate  Body Temperature  Limb Movement  \\\n",
      "0         93.80            25.680            91.840         16.600   \n",
      "1         91.64            25.104            91.552         15.880   \n",
      "2         60.00            20.000            96.000         10.000   \n",
      "3         85.76            23.536            90.768         13.920   \n",
      "4         48.12            17.248            97.872          6.496   \n",
      "\n",
      "   Blood Oxygen  Eye Movement  Sleep Hours  Heart Rate  Stress Levels  \n",
      "0        89.840         99.60        1.840       74.20              1  \n",
      "1        89.552         98.88        1.552       72.76              1  \n",
      "2        95.000         85.00        7.000       60.00              0  \n",
      "3        88.768         96.92        0.768       68.84              1  \n",
      "4        96.248         72.48        8.248       53.12              0  \n"
     ]
    }
   ],
   "source": [
    "# Label Encoding (for ordinal features)\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "df_label_encoded = df.copy()\n",
    "\n",
    "df_label_encoded['Stress Levels'] = label_encoder.fit_transform(df_label_encoded['Stress Levels'])\n",
    "\n",
    "print(\"\\nDataFrame with Label Encoding :\")\n",
    "print(df_label_encoded.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**One-Hot Encoding:** This method creates a binary column for each unique category and assigns a 1 or 0 based on whether a row contains that category. It's generally used for nominal (non-ordinal) categorical variables, like \"stressed\", \"not stressed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame with One-Hot Encoding (Nominal):\n",
      "   Snoring Rate  Respiratory Rate  Body Temperature  Limb Movement  \\\n",
      "0         93.80            25.680            91.840         16.600   \n",
      "1         91.64            25.104            91.552         15.880   \n",
      "2         60.00            20.000            96.000         10.000   \n",
      "3         85.76            23.536            90.768         13.920   \n",
      "4         48.12            17.248            97.872          6.496   \n",
      "\n",
      "   Blood Oxygen  Eye Movement  Sleep Hours  Heart Rate  Stress Levels  \n",
      "0        89.840         99.60        1.840       74.20              1  \n",
      "1        89.552         98.88        1.552       72.76              1  \n",
      "2        95.000         85.00        7.000       60.00              0  \n",
      "3        88.768         96.92        0.768       68.84              1  \n",
      "4        96.248         72.48        8.248       53.12              0  \n"
     ]
    }
   ],
   "source": [
    "df_onehot = df.copy()\n",
    "\n",
    "df_onehot = pd.get_dummies(df_onehot, columns=['Stress Levels'], drop_first=True, prefix='', prefix_sep='', dtype='int')\n",
    "\n",
    "df_onehot.rename(columns={'stressed': 'Stress Levels'}, inplace=True)\n",
    "\n",
    "print(\"\\nDataFrame with One-Hot Encoding (Nominal):\")\n",
    "print(df_onehot.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there would have been 2 columns, not stressed and stressed \\\n",
    "by `drop_first=True`, we drop the first column, as it can be infered from the others \\\n",
    "and stressed is renamed to Stress Levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to remove outliers based on the IQR method\n",
    "def remove_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    # Define the acceptable range\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    # Clip the outliers\n",
    "    df[column] = df[column].clip(lower_bound, upper_bound)\n",
    "\n",
    "\n",
    "df_cleaned = df_onehot.copy()\n",
    "# Apply this function to all relevant columns\n",
    "for col in df_cleaned.columns[:-1]:  # Exclude 'Stress Levels'\n",
    "    remove_outliers(df_cleaned, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What it does:**\n",
    "\n",
    "It limits (or \"clips\") the values in df[column] so that any value below lower_bound is set to lower_bound, and any value above upper_bound is set to upper_bound.\\\n",
    "This keeps all values within the specified range, replacing extreme outliers with the closest boundary value instead of removing them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardize and Normalize Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Snoring Rate  Respiratory Rate  Body Temperature  Limb Movement  \\\n",
      "0      0.887273          0.691429          0.488571       0.840000   \n",
      "1      0.848000          0.650286          0.468000       0.792000   \n",
      "2      0.272727          0.285714          0.785714       0.400000   \n",
      "3      0.741091          0.538286          0.412000       0.661333   \n",
      "4      0.056727          0.089143          0.919429       0.166400   \n",
      "\n",
      "   Blood Oxygen  Eye Movement  Sleep Hours  Heart Rate  Stress Levels  \n",
      "0      0.522667      0.880000     0.204444    0.691429              1  \n",
      "1      0.503467      0.864000     0.172444    0.650286              1  \n",
      "2      0.866667      0.555556     0.777778    0.285714              0  \n",
      "3      0.451200      0.820444     0.085333    0.538286              1  \n",
      "4      0.949867      0.277333     0.916444    0.089143              0  \n"
     ]
    }
   ],
   "source": [
    "# Using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "normalizer = MinMaxScaler()\n",
    "\n",
    "data_standardized = scaler.fit_transform(df_cleaned.drop(columns=['Stress Levels']))\n",
    "data_normalized = normalizer.fit_transform(data_standardized)\n",
    "\n",
    "# Convert back to a DataFrame and add the target column\n",
    "df_scaled_normalized = pd.DataFrame(data_normalized, columns=df_cleaned.columns[:-1])\n",
    "df_scaled_normalized[\"Stress Levels\"] = df_cleaned[\"Stress Levels\"]\n",
    "\n",
    "print(df_scaled_normalized.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This standardizes features to have a mean of 0 and a standard deviation of 1. \\\n",
    "Then normalizes the data to scale it between 0 and 1.\n",
    "\n",
    "## **What Does `fit_transform` Do?**\n",
    "\n",
    "1. **Fit**:  \n",
    "   - Computes the parameters needed for transformation based on the data provided.\n",
    "     - For **StandardScaler**: Calculates mean (\\(\\mu\\)) and standard deviation (\\(\\sigma\\)).\n",
    "     - For **MinMaxScaler**: Calculates the minimum and maximum values.\n",
    "   - These parameters are saved internally to be used later for consistent scaling.\n",
    "\n",
    "2. **Transform**:  \n",
    "   - Applies the transformation using the parameters calculated during the `fit` step.\n",
    "   - Modifies the data accordingly:\n",
    "     - For **StandardScaler**: \n",
    "      $ z = \\frac{(x - \\mu)}{\\sigma} $\n",
    "\n",
    "     - For **MinMaxScaler**: \n",
    "      $ x' = \\frac{(x - \\text{min})}{\\text{max} - \\text{min}} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed dataset saved as 'Human Stress Dataset Preprocessed.csv'\n"
     ]
    }
   ],
   "source": [
    "# Export the final data as csv\n",
    "df_scaled_normalized.to_csv('../Dataset/Human Stress Dataset Preprocessed.csv', index=False)\n",
    "print(\"Preprocessed dataset saved as 'Human Stress Dataset Preprocessed.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape: (504, 8)\n",
      "Testing Data Shape: (126, 8)\n"
     ]
    }
   ],
   "source": [
    "# Define features (X) and target variable (y)\n",
    "X = df.drop(columns=['Stress Levels'])  # Features\n",
    "y = df['Stress Levels']  # Target\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training Data Shape: {X_train.shape}\")\n",
    "print(f\"Testing Data Shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `random_state` parameter is used to ensure reproducibility of the results. By setting a specific value for `random_state`, we ensure that the data is split in the same way every time you run the code. \n",
    "\n",
    "```python\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "```\n",
    "\n",
    "By using `random_state=42`, we ensure that the split of the data into training and testing sets is consistent across different executions of the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the train test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and Test data saved as 'X_train.csv', 'X_test.csv', 'y_train.csv', 'y_test.csv'\n"
     ]
    }
   ],
   "source": [
    "# save the train test data\n",
    "X_train.to_csv('../Dataset/X_train.csv', index=False)\n",
    "X_test.to_csv('../Dataset/X_test.csv', index=False)\n",
    "y_train.to_csv('../Dataset/y_train.csv', index=False)\n",
    "y_test.to_csv('../Dataset/y_test.csv', index=False)\n",
    "print(\"Train and Test data saved as 'X_train.csv', 'X_test.csv', 'y_train.csv', 'y_test.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
